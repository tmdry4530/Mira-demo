---
description: user-scenarios
globs: 
alwaysApply: false
---
# Mira 합의메커니즘 웹앱 - 사용자 시나리오 설계

## 주요 사용자 페르소나

### 🎯 1차 타겟: 대학생 김민수 (22세)
- **배경**: 컴퓨터공학과 3학년, 블록체인/AI에 관심
- **목적**: 새로운 기술 체험, 합의메커니즘 학습
- **기대**: 직관적 인터페이스, 빠른 결과 확인
- **디바이스**: 스마트폰 (80%), 노트북 (20%)

### 🎯 2차 타겟: 기술 기자 이영희 (35세)
- **배경**: IT 매체 기자, 신기술 리뷰 작성
- **목적**: 기술 검증, 기사 작성용 자료 수집
- **기대**: 정확한 결과, 과정의 투명성
- **디바이스**: 노트북 (70%), 태블릿 (30%)

## 핵심 사용자 시나리오

### 📱 시나리오 1: 첫 방문 사용자 (김민수)

```
상황: 친구가 공유한 링크로 첫 방문
시간: 점심시간 (12:00-13:00), 스마트폰 사용
목표: 5분 내로 Mira가 뭔지 이해하고 체험하기
```

**단계별 여정:**

1. **랜딩 (0-30초)**
   - 페이지 로드 → "Mira 합의메커니즘 체험하기" 헤더
   - 간단한 설명 → "AI 답변을 9명이 검증해요!"
   - 예시 질문 버튼들 → "토끼에 대해 알려줘", "지구는 평평한가요?"

2. **질문 입력 (30초-1분)**
   - 예시 질문 "토끼에 대해 알려줘" 클릭
   - 또는 직접 입력: "인공지능이 위험한가요?"
   - 전송 버튼 → 애니메이션과 함께 다음 화면으로

3. **AI 답변 생성 (1-2분)**
   - 로딩 화면: "GPT가 답변을 생성하고 있어요..."
   - 진행률 바 + 예상 시간 표시
   - 생성 완료 → 답변 미리보기

4. **명제 분할 (2-2.5분)**
   - "답변을 검증 가능한 문장으로 나누고 있어요"
   - 원본 → 분할된 명제들 시각화
   - 예: "토끼는 빠르게 달릴 수 있다" / "토끼는 귀가 길다"

5. **검증 과정 (2.5-4분)**
   - 3×3 검증자 그리드 등장
   - 각 검증자가 순차적으로 활성화
   - 실시간 상태: 대기 → 검증중 → 완료(사실/거짓)

6. **결과 확인 (4-5분)**
   - 최종 결과 요약
   - 각 명제별 투표 결과 (7/9 사실, 2/9 거짓)
   - "다시 해보기" 버튼

### 📊 시나리오 2: 기술 검증 (이영희)

```
상황: 기사 작성을 위한 기술 검증
시간: 오후 업무시간, 노트북 사용
목표: 기술의 정확성과 한계 파악
```

**단계별 여정:**

1. **의도적 테스트 질문 입력**
   - "백신이 자폐증을 유발한다" (명백한 거짓)
   - "태양은 동쪽에서 뜬다" (명백한 사실)

2. **검증 과정 면밀히 관찰**
   - 각 검증자의 판단 근거 확인
   - 응답 시간 및 일관성 체크
   - 예외 상황 발생 시 처리 방식 확인

3. **결과 분석 및 기록**
   - 정확도 측정
   - 시스템 한계점 파악
   - 개선 포인트 발견

## 사용자 플로우 다이어그램

```mermaid
graph TD
    A[웹사이트 접속] --> B{첫 방문자?}
    B -->|Yes| C[간단한 소개 + 예시 질문]
    B -->|No| D[질문 입력창]
    
    C --> E[예시 질문 선택 또는 직접 입력]
    D --> E
    E --> F[질문 전송]
    
    F --> G[GPT API 답변 생성]
    G --> H[답변 완료]
    H --> I[Gemini API 명제 분할]
    
    I --> J[분할된 명제 표시]
    J --> K[9개 검증자 그리드 초기화]
    
    K --> L[검증자 1-9 병렬 처리]
    L --> M{모든 검증 완료?}
    M -->|No| N[진행률 업데이트]
    N --> L
    M -->|Yes| O[결과 집계]
    
    O --> P[과반수 판정]
    P --> Q[최종 결과 화면]
    Q --> R{다시 하기?}
    R -->|Yes| D
    R -->|No| S[종료]
```

## 검증 프로세스 상세 다이어그램

```mermaid
sequenceDiagram
    participant U as 사용자
    participant F as Frontend
    participant B as Backend
    participant G as GPT API
    participant V as Gemini API (×9)
    
    U->>F: 질문 입력
    F->>B: 질문 전송
    B->>G: 답변 요청
    G-->>B: AI 답변 반환
    B-->>F: 답변 전달
    F-->>U: 답변 표시
    
    B->>V: 명제 분할 요청
    V-->>B: 분할된 명제들
    B-->>F: 명제 리스트
    F-->>U: 명제 시각화
    
    loop 각 명제에 대해
        par 9개 검증자 병렬 처리
            B->>V: 검증 요청 (검증자 1)
            B->>V: 검증 요청 (검증자 2)
            B->>V: 검증 요청 (검증자 9)
        end
        
        V-->>B: 검증 결과들
        B-->>F: 실시간 업데이트
        F-->>U: 검증 진행률 표시
    end
    
    B->>B: 과반수 판정
    B-->>F: 최종 결과
    F-->>U: 결과 화면 표시
```

## 예외 상황 시나리오

### 🚨 시나리오 3: API 오류 발생

**상황**: 검증 중 일부 API 실패
**대응**: 
- 실패한 검증자는 "재시도 중" 표시
- 3회 재시도 후 "검증 실패" 표시
- 나머지 검증자 결과로 판정 (최소 5개 필요)

### 🚨 시나리오 4: 네트워크 불안정

**상황**: 사용자 네트워크 끊김
**대응**:
- 자동 재연결 시도
- 진행 상황 저장 후 복구
- 친화적 오류 메시지 표시

## UI 상태 다이어그램

```mermaid
stateDiagram-v2
    [*] --> 초기화면
    초기화면 --> 질문입력
    질문입력 --> AI답변생성 : 질문 전송
    AI답변생성 --> 명제분할 : 답변 완료
    명제분할 --> 검증대기 : 분할 완료
    검증대기 --> 검증진행 : 검증자 시작
    검증진행 --> 검증완료 : 모든 검증 완료
    검증완료 --> 결과표시 : 과반수 판정
    결과표시 --> 질문입력 : 다시 하기
    결과표시 --> [*] : 종료
    
    AI답변생성 --> 오류처리 : API 오류
    검증진행 --> 오류처리 : 검증 실패
    오류처리 --> 질문입력 : 재시도
```

## 성공 지표별 시나리오 검증

### ✅ 사용성 테스트
- **첫 사용자 완주율**: 80% 이상
- **평균 완료 시간**: 2분 이내
- **재방문율**: 40% 이상

### ✅ 기능 검증
- **API 성공률**: 95% 이상
- **검증 정확도**: 주관적 질문 제외 90% 이상
- **모바일 호환성**: 완벽 지원

이 시나리오들은 실제 사용자 테스트 시 검증 기준으로 활용되며, 개발 우선순위 결정에도 참고됩니다.

